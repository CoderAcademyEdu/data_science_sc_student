{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Week 3 - Cross Validation\n",
    "\n",
    "---\n",
    "\n",
    "[Top](#ML-Week-3---Cross-Validation) | [Previous section](#ML-Week-3---Cross-Validation) | [Next section](#Part-0:-Quick-review) | [Bottom](#Thank-you)\n",
    "\n",
    "This notebook has the following sections:\n",
    "\n",
    "* [Part 0: Quick review!](#Part-0:-Quick-review)\n",
    "* [Part 1: Introduction to cross-validation](#Part-1:-Introduction-to-cross-validation)\n",
    "* [Part 2: Figuring out the correct complexity - regularisation](#Part-2:-Figuring-out-the-correct-complexity---regularisation)\n",
    "* [Part 3: K-Fold Cross Validation](#Part-3:-K-Fold-Cross-Validation)\n",
    "* [Part 4: Try it yourself](#Part-4:-Try-it-yourself)\n",
    "\n",
    "\n",
    "## Part 0: Quick review\n",
    "---\n",
    "\n",
    "[Top](#ML-Week-3---Cross-Validation) | [Previous section](#ML-Week-3---Cross-Validation) | [Next section](#Part-1:-Introduction-to-cross-validation) | [Bottom](#Thank-you)\n",
    "\n",
    "Let's load up the full [capital bikeshare](https://archive.ics.uci.edu/ml/datasets/bike+sharing+dataset) dataset from last week. We can also use the [`pd.DataFrame.describe()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html) method to begin to understand our data. \n",
    "\n",
    "There is a slight difference within this dataset compared to last week. The `temp` column describes a `normalised` temperature, meaning all temperature values have been **scaled to be between 0 and 1**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "bikeshare_data = pd.read_csv('data/day.csv')\n",
    "\n",
    "# Describe data\n",
    "bikeshare_data.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import some other useful libraries for linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the sklearn linear regression function\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Import plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Import metrics\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Import train_test_split\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "The following code cell uses the [sklearn.linear_model.LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) object to create a function that runs linear regression to predict the `cnt` of people using bikes on a specific day. It then outputs the model.\n",
    "\n",
    "Remember last week how we can raise variables to different powers and increase the complexity of our model. The function defined below allows us to raise any variable by any power. It does this because its input are two different python lists.\n",
    "\n",
    "* The `cols` input is a list of columns that will be used as features for the model. For example, if `cols` is `['workingday', 'hum']`, the regression will use these two columns as features\n",
    "* The `powers` input is a list of the maximum power for each of the columns to be raised to within the model\n",
    "\n",
    "For example, the following function call will create the following linear equation...\n",
    "\n",
    "```python\n",
    "# Inputs\n",
    "cols = ['workingday', 'hum']\n",
    "powers = [3, 2]\n",
    "\n",
    "model = run_linear_regression(data, cols=cols, powers=powers, target='cnt')\n",
    "```\n",
    "\n",
    "Defined as follows...\n",
    "\n",
    "$cnt = m_{workingday}x_{workingday} + m_{workingday^{2}}x^{2}_{workingday} + m_{workingday^{3}}x^{3}_{workingday} + m_{hum}x_{hum} + m_{hum^{2}}x^{2}_{hum} + b$\n",
    "\n",
    "The model will print the resulting MSE, and correlation of the output on a **test set**.\n",
    "\n",
    "There are **gaps** in the function, indicated by comments, specifically where it says `INSERT CODE: ...`. Fill in these gaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_linear_regression(data, cols, powers, target='cnt'):\n",
    "    \"\"\"\n",
    "    Run linear regression on a given feature set, raising to a given power, and predicting\n",
    "    a given target\n",
    "    \n",
    "    :param data: <pd.DataFrame>, the data to be used for linear regression\n",
    "    :param cols: <list>, the columns to use as features\n",
    "    :param powers: <list>, the parameters to use as powers\n",
    "    :param target: <str>, the target variable, defaults to 'cnt' assuming the\n",
    "                   correct preprocessing\n",
    "    \n",
    "    :returns: the trained LinearRegression model\n",
    "    \"\"\"\n",
    "    # Create necessary columns\n",
    "    model_data = data.copy()\n",
    "    \n",
    "    # Go through each column and add the correct powers\n",
    "    for i in range(len(cols)):\n",
    "        # Check if power is > 1\n",
    "        if powers[i] > 1:\n",
    "            for p in range(2, powers[i] + 1):\n",
    "                model_data[cols[i] + '_' + str(p)] = model_data[cols[i]] ** p\n",
    "                # APPEND\n",
    "                cols.append(cols[i] + '_' + str(p))\n",
    "        \n",
    "    \n",
    "    # Create a train test split\n",
    "    train, test = train_test_split(model_data, random_state=42)\n",
    "    \n",
    "    # 1. INSERT CODE: CREATE A LINEAR REGRESSION OBJECT AND STORE THE OBJECT IN A VARIABLE CALLED \"lr\"\n",
    "    lr = 0\n",
    "    \n",
    "    # 2. INSERT CODE: FIT THE LINEAR REGRESSION MODEL TO THE TRAIN DATA, FITTING COLUMNS IN \"cols\"\n",
    "    \n",
    "    \n",
    "    # 3. INSERT CODE: PREDICT THE TEST DATA, USING THE COLUMNS in \"cols\", AND SAVE TO A VARIABLE\n",
    "    #    CALLED Y_PRED\n",
    "    y_pred = 0\n",
    "\n",
    "    \n",
    "    # 4. INSERT CODE: CALCULATE THE MSE USING THE TEST DATA, AND SAVE TO A VARIABLE CALLED \"mse\"\n",
    "    #    REMEMBER TO PREDICT USING ONLY THE COLUMNS DEFINED IN \"cols\"\n",
    "    mse = 0\n",
    "    \n",
    "    \n",
    "    # Calculate the correlation coefficient\n",
    "    r2 = r2_score(test[target], y_pred)\n",
    "    \n",
    "    # Print results\n",
    "    print('The MSE is: %.2f' % mse)\n",
    "    print('The r2 is: %.2f' % r2)\n",
    "    \n",
    "    # return model\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells will run the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup columns\n",
    "cols = ['workingday', 'hum']\n",
    "powers = [3, 2]\n",
    "\n",
    "# Run the model\n",
    "run_linear_regression(data=bikeshare_data, cols=cols, powers=powers, target='cnt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Introduction to cross-validation\n",
    "\n",
    "---\n",
    "[Top](#ML-Week-3---Cross-Validation) | [Previous section](#Part-0:-Quick-review) | [Next section](#Part-2:-Figuring-out-the-correct-complexity---regularisation) | [Bottom](#Thank-you)\n",
    "\n",
    "### Review from last week\n",
    "\n",
    "Last week we began to talk about a new way to test the \"fit\" of a model to data. Remember that we assessed model fit using the **mean squared error**, which measured the average squared distance between our dataset and the model fit to this data.\n",
    "\n",
    "The new method tested the model fit not on the training data, but on a **set of data we held out** of the data, called the **test dataset**.\n",
    "\n",
    "For convenience, let's go back to our **univariate linear regression** model, using just the **temp** for prediction. The following code will run univariate regression multiple times, based upon a **power** term entered into the function. It will then **graph the mse** of the training and testing dataset, compared to the model prediction, as we increase the complexity of the model.\n",
    "\n",
    "\n",
    "For example...\n",
    "\n",
    "**If power=2**: The function will run two linear regressions:\n",
    "\n",
    "* Regression 1: $cnt = m_{temp}x_{temp} + b$\n",
    "* Regression 2: $cnt = m_{temp}x_{temp} + m_{temp^2}x^{2}_{temp} + b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_linear_reg_fit(data, power=1, target='cnt', random_state=30, chart=True):\n",
    "    \"\"\"\n",
    "    Run linear regression multiple times to analyse the power counts\n",
    "    \n",
    "    :param data: <pd.DataFrame>, the data to be fit\n",
    "    :param power: <list>, the parameters to use as maximum power\n",
    "    :param target: <str>, the target variable, defaults to 'cnt' assuming the\n",
    "                   correct preprocessing\n",
    "    :param random_state: <int>, the random state to use for model selection\n",
    "    :param chart: <bool>, whether to create a chart for the model\n",
    "    \n",
    "    :return lrs: list<LinearRegression>, a list of linear regression objects\n",
    "    :return train: <pd.DataFrame>, the specific training data\n",
    "    :return test: <pd.DataFrame>, the specific testing data\n",
    "    \"\"\"\n",
    "    # Create necessary columns\n",
    "    model_data = data.copy()\n",
    "    \n",
    "    # Add columns to fit\n",
    "    cols = ['temp']\n",
    "    \n",
    "    # Go through each column and add the correct powers needed\n",
    "    if power > 1:\n",
    "        for p in range(2, power + 1):\n",
    "            model_data['temp_' + str(p)] = model_data['temp'] ** p\n",
    "            # append\n",
    "            cols.append('temp_' + str(p))\n",
    "\n",
    "    \n",
    "    # Create a train test split\n",
    "    train, test = train_test_split(model_data, random_state=random_state)\n",
    "    \n",
    "    # Fit data towards each power, and calculate MSE\n",
    "    powers = []\n",
    "    mse = []\n",
    "    mse_type = []\n",
    "    lrs = []\n",
    "    \n",
    "    for i in range(1, power + 1):\n",
    "        # Run linear regression\n",
    "        lr = LinearRegression()\n",
    "        # Fit the model\n",
    "        lr.fit(train[cols[0:i]], train[target])\n",
    "        # Get error\n",
    "        powers += [i, i]\n",
    "        mse.append(mean_squared_error(train[target], lr.predict(train[cols[0:i]])) / 1e6)\n",
    "        mse_type.append('Train')\n",
    "        mse.append(mean_squared_error(test[target], lr.predict(test[cols[0:i]])) / 1e6)\n",
    "        mse_type.append('Test')\n",
    "        lrs.append(lr)\n",
    "    \n",
    "    # Graph\n",
    "    if chart:\n",
    "        mse_df = pd.DataFrame({'Max Power': powers, 'MSE': mse, 'Dataset': mse_type})\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        sns.pointplot(x='Max Power', y='MSE', hue='Dataset', data=mse_df, ci=None)\n",
    "        plt.ylabel('MSE (in millions)')\n",
    "        plt.title('Train and Test MSE')\n",
    "    \n",
    "    return lrs, train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the following cell to run the code, and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Power\n",
    "power = 2\n",
    "\n",
    "# Run the code\n",
    "_ = analyse_linear_reg_fit(bikeshare_data, power=power, target='cnt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "The **power** variable defined above increases the maximum complexity of the model tested. What should the maximum complexity of this model be based upon the training and testing error?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation, overfitting and underfitting\n",
    "\n",
    "The **maximum power** of the model, that defines whether we are going to use a linear equation of order 1, or 10, is called a **hyperparameter** of the model. A **hyperparemeter** is something that is set _prior_ to model training. Here's a picture to show you the difference between parameters and hyperparameters within an order 2 linear regression model.\n",
    "\n",
    "---\n",
    "\n",
    "<img src=\"img/Parameters_vs_hyperparameters.png\" width=\"600\">\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "How do we know the correct hyperparameter to use for our model? We choose hyperparemeters based upon what **generalises** well to data that the model was not specifically trained on. In our previous example, we analysed the **MSE** of a **test dataset** that was **held out** from model training to assess what the complexity of our model should be.\n",
    "\n",
    "The process we went through has a name, and it's called **cross-validation**. Here's a definition [from AWS](https://docs.aws.amazon.com/machine-learning/latest/dg/cross-validation.html).\n",
    "\n",
    "> **Cross-validation** is a technique for evaluating ML models by training several ML models on **subsets** of the available input data and evaluating them on the **complementary subset** of the data. Use cross-validation to detect **overfitting**, ie, failing to generalize a pattern.\n",
    "\n",
    "In our case:\n",
    "\n",
    "* **subsets** of the available input data were stored in a variable called `train` that held 80% of our full dataset\n",
    "* The **complementary subset** of the data for evaluating the model was stored in a variable called `test`, which made up 20% of our dataset\n",
    "\n",
    "What does **overfitting mean**? Let's look at some graphs to find out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sample dataset\n",
    "samp_data = bikeshare_data.sample(n=20, random_state=42)\n",
    "\n",
    "# Figures\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Subplot\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.regplot(x='temp', y='cnt', order=1, data=samp_data, ci=None)\n",
    "plt.title('Underfit, Order = 1')\n",
    "plt.xlabel('Normalised Temperature')\n",
    "plt.ylabel('Count of bikes')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.regplot(x='temp', y='cnt', order=3, data=samp_data, ci=None)\n",
    "plt.title('OK Fit, Order = 3')\n",
    "plt.xlabel('Normalised Temperature')\n",
    "plt.ylabel('')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.regplot(x='temp', y='cnt', order=8, data=samp_data, ci=None)\n",
    "plt.title('Overfit, Order = 8')\n",
    "plt.xlabel('Normalised Temperature')\n",
    "plt.ylabel('')\n",
    "\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thought Exercise\n",
    "\n",
    "I used **order = 3** on the model because that is what I found was best on the test set from the previous exercise. Do you think order = 3 is actually best?\n",
    "\n",
    "Let's define some more terms.\n",
    "\n",
    "> An **overfit** model is a model that fits _really well_ on the training dataset used to fit the parameters, but does not generalise well. We saw this when we added **higher orders** to our model. The training MSE decreased, but the test MSE increased. When you read about model overfitting, you might also see that overfit models have **high variance**\n",
    "\n",
    "> An **underfit** model is a model that _does not fit_ the training data well. This might happen with lower order, or in general, less complicated models. You might also see online that underfit models are said to have **high bias**.\n",
    "\n",
    "### Side-note, why bias and variance?\n",
    "\n",
    "Something that often confuses me is why we see the words **bias** and **variance** related to underfitting and overfitting.\n",
    "\n",
    "The word **variance** comes from statistics, and is often used to describe variation in a process. Where does our algorithm have variation? It has variation in the training/test set we chose. The **model fit really well the training set that was sampled**. If we had chosen a different training set, it would have resulted in a **very different** set of trained parameters from what we chose, and a different error if we had kept the original model fit.\n",
    "\n",
    "---\n",
    "\n",
    "<img src='img/High_Variance.png' width='600'>\n",
    "\n",
    "---\n",
    "\n",
    "### Thought exercise\n",
    "\n",
    "Based upon this notion of **high variance**, have we done a good job choosing a test dataset?\n",
    "\n",
    "#### So why bias?\n",
    "\n",
    "The reason we use the word **bias** is because underfit algorithms usually are based upon **our own assumptions** about the simplicity of a model. In underfit models, we assume the model has a certain shape, which restricts the model from training well. Thus, we are putting **our own biases** into the model.\n",
    "\n",
    "There are more mathematical definitions of bias and variance...but we're not going to go there. [Wikipedia does though.](https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff)\n",
    "\n",
    "### A larger issue\n",
    "\n",
    "Unfortunately, as you decrease the variance of a model, you usually increase the bias in a model, and vice versa. We call this issue the **bias-variance trade-off**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Figuring out the correct complexity - regularisation\n",
    "\n",
    "---\n",
    "[Top](#ML-Week-3---Cross-Validation) | [Previous section](#Part-1:-Introduction-to-cross-validation) | [Next section](#Part-3:-K-Fold-Cross-Validation) | [Bottom](#Thank-you)\n",
    "\n",
    "\n",
    "So, let's summarise our cross-validation procedure, based upon our toolkit thus far...\n",
    "\n",
    "\n",
    "```\n",
    "power = inputted higher order power\n",
    "\n",
    "Split training/test sets\n",
    "\n",
    "for each power:\n",
    "    1. Add columns to data with increase complexity\n",
    "    2. Fit model\n",
    "    3. Predict using test set\n",
    "    4. Save error\n",
    "\n",
    "\n",
    "Graph test/train errors. Choose order where the test error starts to increase\n",
    "```\n",
    "\n",
    "Let's say we try powers up to 8. We would fit **8 different** linear models for cross-validation. Namely...\n",
    "\n",
    "* Order 1: $cnt = m_{temp}x_{temp} + b$\n",
    "* ...\n",
    "* Order 8: $cnt = m_{temp^8}x^8_{temp} + m_{temp^7}x^7_{temp} + ... + m_{temp}x_{temp}  + b$\n",
    "\n",
    "\n",
    "### Thought Exercise\n",
    "\n",
    "Let's say we now fit a model with **two variables**, temperature and windspeed. The **first-order** linear model is thus...\n",
    "\n",
    "$$ cnt = m_{temp}x_{temp} + m_{windspeed}x_{windspeed} + b $$\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><span style=\"font-size: 14px; text-align: left\">Let's say we want to fit a multivariate linear regression model <strong>up to order 8</strong> with these two parameters. How many linear regression models would we need to fit, to check everything?</span></td>\n",
    "        <td><img src=\"img/mind_blown.gif\" width=\"500\">\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "As we increase the number of variables...we exponentially increase the number of potential fits to our model. We haven't even explored **non-linear** spaces yet (for example, we make a new column of temperature * windspeed, or $x_{temp}x_{windspeed}$). Wouldn't it be nice if we didn't have to worry about this arduous process of tuning every potential hyperaparemeter space?\n",
    "\n",
    "### Regularisation\n",
    "\n",
    "#### What do model weights represent?\n",
    "\n",
    "Let's run this multivariate regression, simply with this equation...\n",
    "\n",
    "$$ cnt = m_{temp}x_{temp} + m_{windspeed}x_{windspeed} + b $$\n",
    "\n",
    "We'll print out the model coeffcients as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run linear regression\n",
    "lr = LinearRegression()\n",
    "# Fit the model\n",
    "lr.fit(bikeshare_data[['temp', 'windspeed']], bikeshare_data['cnt'])\n",
    "# Get coefficients for the equation\n",
    "print('Final equation: cnt = %.2f * x_temp + %.2f * x_windspeed + %.2f' % (lr.coef_[0], lr.coef_[1], lr.intercept_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thought exercise\n",
    "\n",
    "Look at these coefficients and think about the following...\n",
    "\n",
    "* As the windspeed changes by 1, how much does the count of bikes used change?\n",
    "* As the temperature changes by 1, how much does the count of bikes used change?\n",
    "* If both the windspeed and temperature each change by 1, which has more affect on the count of bikes used?\n",
    "\n",
    "Thus, the **weights affect** how certain variables influence the model. Let's look at the model weights for a **univariate linear regression** of higher order 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the code\n",
    "lrs, _, _ = analyse_linear_reg_fit(bikeshare_data, power=8, target='cnt', chart=False)\n",
    "\n",
    "# Prints coefficients\n",
    "curr = 1\n",
    "for m in lrs[-1].coef_:\n",
    "    print('Order, %d: %.2f' %(curr, m))\n",
    "    curr += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thought...wouldn't it be great if we could implement a way to **shrink the coefficients (weights)** across all parameters just enough, such that we fit the model with the **least amount of complexity necessary** to get the best error?\n",
    "\n",
    "### Regularisation\n",
    "\n",
    "We call methods to simplify the model (and find a balance between overfitting/underfitting) **regularisation**. When we **regularise** models, we usually try to find the right balance of complexity to generalise to the best possible model.\n",
    "\n",
    "For an example, we'll talk today about two types of regularisation for linear regression, specifically **L1 and L2 regularisation**.\n",
    "\n",
    "#### Re-look at MSE\n",
    "\n",
    "Remember that in linear regression, we were trying to **find the coefficients $m_i, b$, that minimise the MSE.** Our MSE equation looked something like this for our **univariate linear regression problem**...\n",
    "\n",
    "$$ MSE = \\frac{1}{N}\\sum_{j=1}^{N}(y_j - [mx_j + b])^2 $$\n",
    "\n",
    "This assumed we have...\n",
    "\n",
    "* N training examples\n",
    "* 2 parameters ($m$ and $b$) in the model\n",
    "* The model outputs a prediction based upon the equation $f(x_j) = mx_j + b$\n",
    "\n",
    "Thus, our problem for linear regression, is find the $m, b$ such that we...\n",
    "\n",
    "$$ \\min \\Big (\\frac{1}{N}\\sum_{j=1}^{N}(y_j - [mx_j + b])^2 \\Big ) $$\n",
    "\n",
    "\n",
    "### L1 Regularisation (lasso regression)\n",
    "\n",
    "\n",
    "Let's add an additional parameter, called $\\alpha$ (prounounced al-fuh) into this minimisation equation. We will add it such that the new equation looks as follows...\n",
    "\n",
    "$$ \\min \\Big (\\frac{1}{N}\\sum_{j=1}^{N}(y_j - [mx_j + b])^2 + \\alpha(|m| + |b|) \\Big ) $$\n",
    "\n",
    "\n",
    "#### Side-note...\n",
    "\n",
    "In case you don't know, $|x|$ is the **absolute value** operator. It makes numbers positive. For example...\n",
    "\n",
    "* $|-3| = 3$\n",
    "* $|4| = 4$\n",
    "\n",
    "### Thought exercise\n",
    "\n",
    "How do you think $\\alpha$ affects $m$ and $b$?\n",
    "\n",
    "Let's test it out. We'll run two linear regressions, fitting our **8th order model**, with this additional $\\alpha$ parameter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the code, generalise 8th order moderl\n",
    "lrs, train, _ = analyse_linear_reg_fit(bikeshare_data, power=8, target='cnt', chart=False)\n",
    "\n",
    "# Now run the code, using the alpha parameter\n",
    "from sklearn.linear_model import Lasso\n",
    "lass_reg = Lasso(alpha=0.1)\n",
    "lass_reg.fit(X=train[['temp'] + ['temp_' + str(i) for i in range(2, 9)]], y=train['cnt'])\n",
    "\n",
    "# Make df\n",
    "coeff_df = pd.DataFrame({'Order': range(1, 9), 'Regular': lrs[-1].coef_, 'Lasso': lass_reg.coef_})\n",
    "coeff_df[['Order', 'Regular', 'Lasso']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So...adding alpha **decreases the weights**, and even better, it begins to decrease higher order terms to $~0$. This is because the overall benefit to lowering the MSE is not substantial enough to include the higher order terms. \n",
    "\n",
    "We call the linear regression regularisation using an absolute value term **L1 regularisation, or lasso regression**, and you can use the [sklearn Lasso object](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html) to run this linear regression.\n",
    "\n",
    "### L2 Regularisation (ridge regression)\n",
    "\n",
    "There is one other type of well-known regularisation used in linear regression, called **L2 regularisation, or ridge regression**. The main difference between this regularisation, and what we just did, is that it **squares** the model parameters instead of taking an absolute value, such that our minimisation equation looks like so...\n",
    "\n",
    "$$ \\min \\Big (\\frac{1}{N}\\sum_{j=1}^{N}(y_j - [mx_j + b])^2 + \\alpha(m^2 + b^2) \\Big ) $$\n",
    "\n",
    "How do you think ridge regression will affect the model parameters, compared to lasso regression?\n",
    "\n",
    "Let's take a look! Run the following code, which will again run regular regression, lasso regression, and now add ridge regression. We'll use the [sklearn Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html) object to run this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the code, generalise 8th order moderl\n",
    "lrs, train, _ = analyse_linear_reg_fit(bikeshare_data, power=8, target='cnt', chart=False)\n",
    "\n",
    "# Prints coefficients\n",
    "lass_reg = Lasso(alpha=0.1)\n",
    "lass_reg.fit(X=train[['temp'] + ['temp_' + str(i) for i in range(2, 9)]], y=train['cnt'])\n",
    "\n",
    "# Run ridge regression\n",
    "from sklearn.linear_model import Ridge\n",
    "ridge_reg = Ridge(alpha=0.1)\n",
    "ridge_reg.fit(X=train[['temp'] + ['temp_' + str(i) for i in range(2, 9)]], y=train['cnt'])\n",
    "\n",
    "\n",
    "# Make df\n",
    "coeff_df = pd.DataFrame({\n",
    "    'Order': range(1, 9), \n",
    "    'Regular': lrs[-1].coef_, \n",
    "    'Lasso': lass_reg.coef_,\n",
    "    'Ridge': ridge_reg.coef_\n",
    "})\n",
    "coeff_df[['Order', 'Regular', 'Lasso', 'Ridge']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thought exercise\n",
    "\n",
    "If we increase the value of alpha, what will happen to our model weights? Will they get bigger or smaller?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: K-Fold Cross Validation\n",
    "\n",
    "---\n",
    "[Top](#ML-Week-3---Cross-Validation) | [Previous section](#Part-2:-Figuring-out-the-correct-complexity---regularisation) | [Next section](#Part-4:-Try-it-yourself) | [Bottom](#Thank-you)\n",
    "\n",
    "One more topic prior to heading off for the evening. Let's go back to the thought exercise from before (if you aren't tired of thinking).\n",
    "\n",
    "> ### Re-thought, thought exercise\n",
    "> Based upon this notion of high variance, have we done a good job choosing a test dataset?\n",
    "\n",
    "Let's analyse this. We'll go back to our `analyse_linear_reg_fit` function. There is a parameter in our `analyse_linear_reg_fit` function, called `random_state`, that can be used to **change** how we split-up our test and training set. Let's play with this parameter a bit. How does it affect the consistency of our model performance when we raise the complexity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Power\n",
    "random_state = 42\n",
    "# Run the code\n",
    "_ = analyse_linear_reg_fit(bikeshare_data, power=5, target='cnt', random_state=random_state)\n",
    "\n",
    "# Power\n",
    "random_state = 30\n",
    "# Run the code\n",
    "_ = analyse_linear_reg_fit(bikeshare_data, power=5, target='cnt', random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some craziness occurs...we get **different results** based upon the **specific training and test sets** that we use. There's some stats bucketed-in that can explain this (based upon whether the traiing/testing datasets have the same  distributions across columns), which we're not going to get into. \n",
    "\n",
    "What we will do, is try to dig into a method that will help us feel more comfortable in estimating model performance.\n",
    "\n",
    "### Adding multiple testing sets\n",
    "\n",
    "To create the training and test sets, we **randomly split the data** into two different datasets. The issue is, the specific split will dictate our model performance, as we saw with the past example.\n",
    "\n",
    "So how do we know if a model generalises well to any new data? Well...let's think about an analogy. If you conduct a survey, you don't conduct a survey by surveying a single person, you survey a **large group of people**, and hope that the more and more people you survey, the more likely the results reflect the overall population.\n",
    "\n",
    "![](https://cdn-images-1.medium.com/max/1600/1*WyCRRXiHvPN3k2ZgjXoK_g.png)\n",
    "\n",
    "We can think of a specific train/test split as a single survey data point. Ideally, we'd love to create **multiple train/test splits**, and look at the results of generating models across these different samples, to be able to get a better idea of how our model will perform on **new data**. Another word for these different splits, are **folds**.\n",
    "\n",
    "If we train on **k different splits**, we create **k-folds**. We call this overall process **k-fold cross-validation**.\n",
    "\n",
    "Here's an example of splitting the datasets into **5 different folds**. We choose a fold to hold-out of our model-fitting within each iteration of training. This leads us to create **five different models**. What we can then do is generate a MSE on the specific test dataset held-out, generating a sample of MSE's from each fold. We can then take an average of the MSE's trained across each fold, and describe the final result in terms of the mean and standard deviation of the MSE's.\n",
    "\n",
    "Here's a visual to help.\n",
    "\n",
    "<img src=\"img/K_Fold_Cross_Val.png\" width=\"700\">\n",
    "\n",
    "Note, in this case, we will call **test set** the **validation set**. You might see different definitions of training, test and validation sets online. Typically...\n",
    "\n",
    "* Training sets fit the model\n",
    "* Validation sets tune hyperparameters\n",
    "\n",
    "Let's run some code...the code will run **10-fold** cross-validation, using the [cross_val_score module](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score) module. If you wanted to explicitely create K-Folds, you could use the [K Fold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold) module. The code will create...\n",
    "\n",
    "* 10 different splits within the dataset, where each split is 10% of the data\n",
    "* It will run linear regression on each of these splits, using the MSE as an error metric on the set held out...\n",
    "* It will then report the mean/std of the MSE, and graph the distributions of the MSE on a plot, per power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def lin_regress_w_k_cross_val(data, power=1, target='cnt', chart=True, cv=10):\n",
    "    \"\"\"\n",
    "    Run linear regression with kfold cross validation to analyse error\n",
    "    \n",
    "    :param power: <list>, the parameters to use as powers\n",
    "    :param target: <str>, the target variable, defaults to 'cnt' assuming the\n",
    "                   correct preprocessing\n",
    "    :param chart: <bool>, whether to create a chart for the model\n",
    "    :param cv: <int>, the number of folds\n",
    "    \n",
    "    :return lrs: list<LinearRegression>, a list of linear regression objects\n",
    "    \"\"\"\n",
    "    # Create necessary columns\n",
    "    model_data = data.copy()\n",
    "    \n",
    "    # Add columns to fit\n",
    "    cols = ['temp']\n",
    "    \n",
    "    # Go through each column and add the correct powers needed\n",
    "    if power > 1:\n",
    "        for p in range(2, power + 1):\n",
    "            model_data['temp_' + str(p)] = model_data['temp'] ** p\n",
    "            # append\n",
    "            cols.append('temp_' + str(p))\n",
    "    \n",
    "    # Fit data towards each power, and calculate MSE\n",
    "    powers = []\n",
    "    mse = []\n",
    "    \n",
    "    # Get linear regression\n",
    "    lr = LinearRegression()\n",
    "    \n",
    "    for i in range(1, power + 1):\n",
    "        # Run linear regression and cross validation\n",
    "        mse += (cross_val_score(\n",
    "            lr, model_data[cols[0:i]], y=model_data[target], scoring='neg_mean_squared_error', cv=cv\n",
    "        ) * -1).tolist()\n",
    "        # Get metrics\n",
    "        powers += [i] * cv\n",
    "        \n",
    "    # Graph\n",
    "    if chart:\n",
    "        mse_df = pd.DataFrame({'Max Power': powers, 'MSE': mse})\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        sns.pointplot(x='Max Power', y='MSE', data=mse_df, ci=68)\n",
    "        plt.ylabel('MSE')\n",
    "        plt.title('Cross Validation Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run linear regression with k fold cross-validation\n",
    "lin_regress_w_k_cross_val(bikeshare_data, power=10, target='cnt', chart=True, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we decide which power we want (in this case, the 2nd power), we would normally train on the **full dataset**. Notice how using the 2nd power makes **qualitative sense with our understanding of temperature** as well!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Try it yourself\n",
    "\n",
    "---\n",
    "[Top](#ML-Week-3---Cross-Validation) | [Previous section](#Part-3:-K-Fold-Cross-Validation) | [Next section](#Thank-you) | [Bottom](#Thank-you)\n",
    "\n",
    "We've done quite a bit. Let's review...\n",
    "\n",
    "* We've analysed and seen the concepts of overfitting and underfitting, and come up with a procedure to choose the best model hyperparameters\n",
    "* We then analysed more automated ways to choose these parameters, using regularisation\n",
    "* And lastly, we created a broader cross-validation procedure, to try to help us feel comfortable with our results\n",
    "\n",
    "We'll put it all together with the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_regress_w_full_cross_val(\n",
    "    data, \n",
    "    cols=['temp'],\n",
    "    max_powers=[1],\n",
    "    regression_type=None,\n",
    "    target='cnt',\n",
    "    chart=True, \n",
    "    cv=10,\n",
    "    final_regression=0\n",
    "):\n",
    "    \"\"\"\n",
    "    Run linear regression with kfold cross validation to analyse error. We will be able to choose\n",
    "    the type of regression, the columns we want within our model, and the maximum power.\n",
    "    \n",
    "    :param data: <pd.DataFrame>, the data for our model\n",
    "    :param cols: list<str>, a list of columns to use in our model\n",
    "    :param max_powers: list<int>, the max power to use for a corresponding column\n",
    "    :param regression_type: <str>, either None (regular), 'lasso', or 'ridge'\n",
    "    :param target: <str>, the target variable, defaults to 'cnt' assuming the\n",
    "                   correct preprocessing\n",
    "    :param chart: <bool>, whether to create a chart for the model\n",
    "    :param cv: <int>, the number of folds\n",
    "    :param final_regression: <int>, the final regression model to run. Indicates max power\n",
    "    \n",
    "    <OPTIONAL RETURN>\n",
    "    :return lr: LinearRegression, the linear regression final model\n",
    "    :return model_data: pd.DataFrame, the specific model data used to fit the returned regression model\n",
    "    \"\"\"\n",
    "    # Create necessary columns\n",
    "    model_data = data.copy()\n",
    "    \n",
    "    # Create columns dict\n",
    "    all_cols = dict()\n",
    "    all_cols[1] = cols[:]\n",
    "    \n",
    "    # Go through each column and add the correct powers needed\n",
    "    for i in range(len(cols)):\n",
    "        all_cols\n",
    "        if max_powers[i] > 1:\n",
    "            for p in range(2, max_powers[i] + 1):\n",
    "                if p not in all_cols.keys():\n",
    "                    all_cols[p] = []\n",
    "                model_data[cols[i] + '_' + str(p)] = model_data[cols[i]] ** p\n",
    "                # Append to columns list\n",
    "                all_cols[p].append(cols[i] + '_' + str(p))\n",
    "                \n",
    "    # Add on all keys\n",
    "    for i in range(2, len(all_cols.keys()) + 1):\n",
    "        all_cols[i] += all_cols[i - 1]\n",
    "                    \n",
    "    # Fit data towards each power, and calculate MSE\n",
    "    powers = []\n",
    "    mse = []\n",
    "    \n",
    "    # Get linear regression\n",
    "    if regression_type == 'lasso':\n",
    "        lr = Lasso(alpha=1.0)\n",
    "    elif regression_type == 'ridge':\n",
    "        lr = Ridge(alpha=0.1)\n",
    "    else:\n",
    "        lr = LinearRegression()\n",
    "    \n",
    "    for i in range(1, max(max_powers) + 1):\n",
    "        # Run linear regression and cross validation\n",
    "        mse += (cross_val_score(\n",
    "            lr, model_data[all_cols[i]], y=model_data[target], scoring='neg_mean_squared_error', cv=cv\n",
    "        ) * -1).tolist()\n",
    "        # Get metrics\n",
    "        powers += [i] * cv\n",
    "        \n",
    "    # Graph\n",
    "    curr = 0\n",
    "    fig, axs = plt.subplots(len(cols) + 1, 1, figsize=(15, (len(cols) + 1) * 4))\n",
    "    if chart:\n",
    "        mse_df = pd.DataFrame({'Max Power': powers, 'MSE': mse})\n",
    "        sns.pointplot(x='Max Power', y='MSE', data=mse_df, ci=68, ax=axs[curr])\n",
    "        \n",
    "    # Final model\n",
    "    curr += 1\n",
    "    if final_regression > 0:\n",
    "        # Fit\n",
    "        lr.fit(model_data[all_cols[final_regression]], model_data[target])\n",
    "        \n",
    "        # Graph\n",
    "        for i in range(len(cols)):\n",
    "            sns.regplot(\n",
    "                x=cols[i], \n",
    "                y=target, \n",
    "                data=model_data, \n",
    "                order=min(final_regression, max_powers[i]), \n",
    "                ci=None, \n",
    "                ax=axs[curr]\n",
    "            )\n",
    "            curr += 1\n",
    "\n",
    "        return lr, model_data[all_cols[final_regression] + [target]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Train the following model and run cross-validation. The inputs are as follows:\n",
    "\n",
    "* `cols` is a list of columns, for example `['temp', 'windspeed', 'hum']`\n",
    "* `max_powers` is a list of maximum powers to use within the model for each columns, for example `[3, 1, 2]`\n",
    "* `regression_type` can be `None` for regular regression, `'lasso'`, or `'ridge'`\n",
    "* `final_regression`, is either 0, or an integer. This dictates the highest power to include on the final regression model, which is returned. \n",
    "\n",
    "The final model is returned based upon the power specifically defined by `final_regression`, as well as the final dataset with all columns used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust columns\n",
    "cols = ['temp', 'windspeed', 'hum']\n",
    "max_powers = [3, 1, 2]\n",
    "regression_type = 'ridge'\n",
    "\n",
    "# Run regression\n",
    "lr, training_data = lin_regress_w_full_cross_val(\n",
    "    bikeshare_data, \n",
    "    cols=cols,\n",
    "    max_powers=max_powers,\n",
    "    regression_type=regression_type,\n",
    "    target='cnt',\n",
    "    chart=True, \n",
    "    cv=10,\n",
    "    final_regression=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Exercise\n",
    "\n",
    "Let's introduce another dataset. I scraped the stock prices from Atlassian for a year and saved them to a file. You can easily do this using [Yahoo Finance](https://finance.yahoo.com/quote/TEAM/history?period1=1526911200&period2=1558447200&interval=1d&filter=history&frequency=1d) yourself. The dataset has the following columns:\n",
    "\n",
    "| Column | Description |\n",
    "|--------|-------------|\n",
    "| Date | The date the price was reocrded |\n",
    "| Close_M1 | The closing stock price one day _prior_ to the current day |\n",
    "| Volume | The number of shares traded throughout the day |\n",
    "| Open | The opening price |\n",
    "| High | The highest price thorughout the day |\n",
    "| Low | The lowest price throughout the day |\n",
    "| Close | The closing price that day |\n",
    "\n",
    "Let's load the data and graph the price for the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "atlassian_data = pd.read_csv('data/atlassian_data_1_year.csv')\n",
    "\n",
    "# Graph\n",
    "plt.figure(figsize=(15, 5))\n",
    "sns.lineplot(x='Date', y='Close', data=atlassian_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your goal...\n",
    "\n",
    "Can you use the features to **develop a linear regression model to predict the \"Close\" price on a given day?** Why might this work well on this dataset but not others? Feel free to create new features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Adjust columns\n",
    "cols = ['Close_M1']\n",
    "max_powers = [3]\n",
    "regression_type = 'ridge'\n",
    "\n",
    "# Run regression\n",
    "lr, training_data = lin_regress_w_full_cross_val(\n",
    "    atlassian_data, \n",
    "    cols=cols,\n",
    "    max_powers=max_powers,\n",
    "    regression_type=regression_type,\n",
    "    target='Close',\n",
    "    chart=True, \n",
    "    cv=10,\n",
    "    final_regression=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thank you\n",
    "\n",
    "[Top](#ML-Week-3---Cross-Validation) | [Previous section](#Part-4:-Try-it-yourself) | [Next section](#Thank-you) | [Bottom](#Thank-you)\n",
    "\n",
    "That concludes our week 3 lesson. Hopefully you enjoyed :)\n",
    "\n",
    "### Downloading the notebook\n",
    "\n",
    "If you would like to retain your work, please follow the following directions:\n",
    "* On the top of this screen, in the header menu, click \"File\", then \"Download as\" and then \"Notebook\".\n",
    "* You will need to download [Python 3.7 with Anaconda](https://www.anaconda.com/distribution/#download-section) to use this in the future"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
